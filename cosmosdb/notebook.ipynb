{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG With CosmosDB\n",
    "\n",
    "In this sample, we'll demonstrate how to build a RAG Pattern application using a subset of the Movie Lens dataset. This sample will leverage the Python SDK for Azure Cosmos DB for NoSQL to perform vector search for RAG, store and retrieve chat history, and store the vectors of the chat history to use as a semantic cache. Azure OpenAI to generate embeddings and LLM completions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requierements\n",
    "\n",
    "%pip install -r requierements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load environments variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "env_name = \".env\" # following sample_env.env template change to your own .env file name\n",
    "config = dotenv_values(env_name)\n",
    "\n",
    "OPENAI_API_KEY = config['openai_key']\n",
    "OPENAI_API_ENDPOINT = config['openai_endpoint']\n",
    "OPENAI_API_VERSION = config['openai_api_version'] # at the time of authoring, the api version is 2024-02-01\n",
    "COMPLETIONS_MODEL_DEPLOYMENT_NAME = config['openai_completions_deployment']\n",
    "EMBEDDING_MODEL_DEPLOYMENT_NAME = config['openai_embeddings_model']\n",
    "COSMOSDB_NOSQL_ACCOUNT_KEY = config['cosmos_key']\n",
    "COSMOSDB_NOSQL_ACCOUNT_ENDPOINT = config['cosmos_uri']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate the Azure Open AI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "AOAI_client = AzureOpenAI(api_key=OPENAI_API_KEY, azure_endpoint=OPENAI_API_ENDPOINT, api_version=OPENAI_API_VERSION,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Embedding\n",
    "\n",
    "We'll use the deployed embeddings model to generate the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def generate_embeddings(text):\n",
    "    '''\n",
    "    Generate embeddings from string of text.\n",
    "    This will be used to vectorize data and user input for interactions with Azure OpenAI.\n",
    "    '''\n",
    "    response = AOAI_client.embeddings.create(input=text, model=EMBEDDING_MODEL_DEPLOYMENT_NAME)\n",
    "    embeddings =response.model_dump()\n",
    "    time.sleep(0.5) \n",
    "    return embeddings['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data with embeddings or generate embeddings\n",
    "\n",
    "We have a sample data file with embeddings but you can generate the embeddings afresh before uploading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load text-sample_w_embeddings.json which has embeddings pre-computed\n",
    "data_file = open(file=\"./text-sample.json\", mode=\"r\") \n",
    "\n",
    "# OR Load text-sample.json data file. Embeddings will need to be generated using the function below.\n",
    "# data_file = open(file=\"../../DataSet/AzureServices/text-sample.json\", mode=\"r\")\n",
    "\n",
    "data = json.load(data_file)\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"1\",\n",
      "  \"title\": \"Azure App Service\",\n",
      "  \"content\": \"Azure App Service is a fully managed platform for building, deploying, and scaling web apps. You can host web apps, mobile app backends, and RESTful APIs. It supports a variety of programming languages and frameworks, such as .NET, Java, Node.js, Python, and PHP. The service offers built-in auto-scaling and load balancing capabilities. It also provides integration with other Azure services, such as Azure DevOps, GitHub, and Bitbucket.\",\n",
      "  \"category\": \"Web\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Take a peek at one data item\n",
    "print(json.dumps(data[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for title and content fields\n",
    "n = 0\n",
    "for item in data:\n",
    "    n+=1\n",
    "    item['id'] = str(n)\n",
    "    title = item['title']\n",
    "    content = item['content']\n",
    "    title_embeddings = generate_embeddings(title)\n",
    "    content_embeddings = generate_embeddings(content)\n",
    "    item['titleVector'] = title_embeddings\n",
    "    item['contentVector'] = content_embeddings\n",
    "    item['@search.action'] = 'upload'\n",
    "    print(\"Creating embeddings for item:\", n, \"/\" ,len(data), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings to sample_text_w_embeddings.json file\n",
    "with open(\"./text-sample_w_embeddings.json\", \"w\") as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create cosmosdb client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.exceptions import AzureError\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "#Cosmos DB imports\n",
    "from azure.cosmos import CosmosClient\n",
    "from azure.cosmos.aio import CosmosClient as CosmosAsyncClient\n",
    "from azure.cosmos import PartitionKey, exceptions\n",
    "\n",
    "cosmos_client = CosmosClient(url=COSMOSDB_NOSQL_ACCOUNT_ENDPOINT, credential=COSMOSDB_NOSQL_ACCOUNT_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new database or use existing one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": \"vector-nosql-db\", \"_rid\": \"WZhzAA==\", \"_self\": \"dbs/WZhzAA==/\", \"_etag\": \"\\\"00006955-0000-0200-0000-678675650000\\\"\", \"_colls\": \"colls/\", \"_users\": \"users/\", \"_ts\": 1736865125}\n"
     ]
    }
   ],
   "source": [
    "#create database\n",
    "DATABASE_NAME = \"vector-nosql-db\"\n",
    "db= cosmos_client.create_database_if_not_exists(\n",
    "    id=DATABASE_NAME\n",
    ")\n",
    "properties = db.read()\n",
    "print(json.dumps(properties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author the vector embedding policy\n",
    "\n",
    "Vector embedding policy defines the necessary information for the vector search queries as detailed below:\n",
    "\n",
    "<ul>\n",
    "  <li>“path”: what properties contain vectors</li>\n",
    "  <li>“datatype”: What type are the vector’s elements (default Float32)</li>\n",
    "  <li>“dimensions”: The length of each vector in the path (default 1536)</li>\n",
    "  <li>“distanceFunction”: The metric used to compute distance/similarity (default Cosine)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_embedding_policy = {\n",
    "    \"vectorEmbeddings\": [\n",
    "        {\n",
    "            \"path\":\"/titleVector\",\n",
    "            \"dataType\":\"float32\",\n",
    "            \"distanceFunction\":\"dotproduct\",\n",
    "            \"dimensions\":1536\n",
    "        },\n",
    "        {\n",
    "            \"path\":\"/contentVector\",\n",
    "            \"dataType\":\"float32\",\n",
    "            \"distanceFunction\":\"cosine\",\n",
    "            \"dimensions\":1536\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing_policy = {\n",
    "    \"includedPaths\": [\n",
    "        {\n",
    "            \"path\": \"/*\"\n",
    "        }\n",
    "    ],\n",
    "    \"excludedPaths\": [\n",
    "        {\n",
    "            \"path\": \"/\\\"_etag\\\"/?\"\n",
    "        },\n",
    "        {\n",
    "            \"path\": \"/titleVector/*\"\n",
    "        },\n",
    "        {\n",
    "            \"path\": \"/contentVector/*\"\n",
    "        }\n",
    "    ],\n",
    "    \"vectorIndexes\": [\n",
    "        {\"path\": \"/titleVector\",\n",
    "         \"type\": \"quantizedFlat\"\n",
    "        },\n",
    "        {\"path\": \"/contentVector\",\n",
    "         \"type\": \"quantizedFlat\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create container with the embedding and indexing policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTAINER_NAME = \"vector-nosql-cont\"\n",
    "try:    \n",
    "    container = db.create_container_if_not_exists(\n",
    "                    id=CONTAINER_NAME,\n",
    "                    partition_key=PartitionKey(path='/id', kind='Hash'),\n",
    "                    indexing_policy=indexing_policy,\n",
    "                    vector_embedding_policy=vector_embedding_policy)\n",
    "\n",
    "    print('Container with id \\'{0}\\' created'.format(id))\n",
    "\n",
    "except exceptions.CosmosResourceExistsError:\n",
    "    print('A container with id \\'{0}\\' already exists'.format(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = db.get_container_client(CONTAINER_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload data to the container\n",
    "\n",
    "Azure Cosmos DB Python SDK does not currently support bulk inserts so we'll have to insert the items sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./text-sample_w_embeddings.json') as f:\n",
    "   data = json.load(f)\n",
    "\n",
    "container_client = db.get_container_client(CONTAINER_NAME)\n",
    "\n",
    "for item in data:\n",
    "    print(\"writing item \", item['id'])\n",
    "    container_client.upsert_item(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector search in Azure Cosmos DB for NoSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to assist with vector search\n",
    "def vector_search(query, num_results=5):\n",
    "    query_embedding = generate_embeddings(query)\n",
    "    results = container.query_items(\n",
    "            query='SELECT TOP @num_results c.content, c.title, c.category, VectorDistance(c.contentVector,@embedding) AS SimilarityScore  FROM c ORDER BY VectorDistance(c.contentVector,@embedding)',\n",
    "            parameters=[\n",
    "                {\"name\": \"@embedding\", \"value\": query_embedding}, \n",
    "                {\"name\": \"@num_results\", \"value\": num_results} \n",
    "            ],\n",
    "            enable_cross_partition_query=True)\n",
    "    #correct this\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are some NoSQL databases in Azure?\"#\"What are the services for running ML models?\"\n",
    "results = vector_search(query)\n",
    "\n",
    "for result in results: \n",
    "    #print(result)\n",
    "    print(f\"Similarity Score: {result['SimilarityScore']}\")  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A over the data with GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_completion(vector_search_results, user_prompt):\n",
    "    system_prompt = '''\n",
    "    You are an intelligent assistant for Microsoft Azure services.\n",
    "    You are designed to provide helpful answers to user questions about Azure services given the information about to be provided.\n",
    "        - Only answer questions related to the information provided below, provide at least 3 clear suggestions in a list format.\n",
    "        - Write two lines of whitespace between each answer in the list.\n",
    "        - If you're unsure of an answer, you can say \"\"I don't know\"\" or \"\"I'm not sure\"\" and recommend users search themselves.\"\n",
    "        - Only provide answers that have products that are part of Microsoft Azure and part of these following prompts.\n",
    "    '''\n",
    "\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    for item in vector_search_results:\n",
    "        messages.append({\"role\": \"system\", \"content\": item['content']})\n",
    "    messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "    response = AOAI_client.chat.completions.create(model=COMPLETIONS_MODEL_DEPLOYMENT_NAME, messages=messages,temperature=0)\n",
    "    \n",
    "    return response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"What are some NoSQL databases in Azure?\"\n",
    "\n",
    "search_results = vector_search(user_input)\n",
    "completions_results = generate_completion(search_results, user_input)\n",
    "print(\"\\n\")\n",
    "print(completions_results['choices'][0]['message']['content'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"What are some benefit of Neo4j\"\n",
    "\n",
    "search_results = vector_search(user_input)\n",
    "completions_results = generate_completion(search_results, user_input)\n",
    "print(\"\\n\")\n",
    "print(completions_results['choices'][0]['message']['content'])    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
