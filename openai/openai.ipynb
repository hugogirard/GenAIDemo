{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Official OpenAI SDK in Python\n",
    "\n",
    "Welcome to this notebook! In this notebook, we will be using the official OpenAI SDK in Python to interact with OpenAI's powerful language models. The SDK provides a simple and efficient way to access the capabilities of OpenAI's models, enabling us to perform a variety of tasks such as text generation, completion, and more.\n",
    "\n",
    "## ðŸ“¦ Installation\n",
    "\n",
    "First, let's install the OpenAI SDK. You can do this using pip.\n",
    "\n",
    "## ðŸ“ Usage\n",
    "\n",
    "Once the SDK is installed, you can start using it in your Python code. Set your OpenAI API key and make requests to the OpenAI API to get responses from the language models.\n",
    "\n",
    "## ðŸ“š Documentation\n",
    "\n",
    "For more detailed information on how to use the OpenAI SDK, please refer to the official documentation.\n",
    "\n",
    "Happy coding! ðŸŽ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai==1.58.1\n",
    "%pip install python-dotenv==1.0.1\n",
    "%pip install pandas==2.2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "chat_deployment_name = os.getenv(\"CHAT_DEPLOYMENT_NAME\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "base_url = os.getenv(\"OPENAI_BASE_URL\")\n",
    "embedding_model=os.getenv(\"EMBEDDING_MODEL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-Akc39DcPtiTbgSDgesHkcZ8PVlj3v\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Sure! Here are 5 funny and light-hearted facts about Quebec City:\\n\\n1. **Unmistakable Loophole for Winter Weather**: Quebecers love to joke about their relationship with cold weather. Since winters are so harsh, thereâ€™s a saying that \\\"If you can survive a Quebec winter, youâ€™re ready for any apocalypse.\\\" Itâ€™s worn as a badge of honor, but locals also find humor in how tourists show up grossly unpreparedâ€”rocking sneakers in six feet of snow!\\n\\n2. **The Endless Poutine Debate**: Quebec City residents take their poutine seriously, but youâ€™d be surprised how intense and hilarious the debate gets about which restaurant makes the *ultimate* poutine. People will passionately argue whether it's the squeakiness of the cheese curds or the gravy texture that truly makes or breaks it, with some local spots claiming their poutine is nothing short of a masterpiece!\\n\\n3. **Beware of the Bonhomme de Neige!**: The famous Bonhomme Carnaval is the mascot of the Quebec Winter Carnival, but hereâ€™s the funny part: some kids find him downright terrifying. While tourists eagerly take selfies, many local children have a â€œfeverish respectâ€ for the giant snowman, whispering legends of his magical powers! Whoâ€™s to say a walking snowman isnâ€™t a bit creepy?\\n\\n4. **An Obsession with the ChÃ¢teau Frontenac**: Quebec City is home to the ChÃ¢teau Frontenac, often called the \\\"most photographed hotel in the world.\\\" Locals will jokingly tell you that every single tourist photo includes this iconic landmarkâ€”even accidentally. Some even claim that the city has a law where youâ€™re required to take at least one photo of the ChÃ¢teau before you're allowed to leave!\\n\\n5. **Escargot? Mais, Non!**: Tourists sometimes think Quebec Cityâ€™s cuisine is super fancy and assume everyone eats escargot (snails) and foie gras every day. Locals love to chuckle at this stereotype, jokingly telling visitors, â€œWe only eat escargot when poutine isnâ€™t an option!â€ Spoiler alert: theyâ€™re more likely enjoying a big plate of comfort food than haute cuisine on a casual night.\\n\\nHope these bring a smile to your face! ðŸŽ‰\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\"\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"protected_material_code\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"protected_material_text\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1735672715,\n",
      "  \"model\": \"gpt-4o-2024-11-20\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": \"fp_82ce25c0d4\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 463,\n",
      "    \"prompt_tokens\": 27,\n",
      "    \"total_tokens\": 490,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"jailbreak\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI  \n",
    "\n",
    "client = AzureOpenAI(api_key=api_key, azure_endpoint=base_url, api_version=\"2024-08-01-preview\")\n",
    "\n",
    "chat_history = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me 5 funny fact about Quebec City.\"\n",
    "        }\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=chat_deployment_name,\n",
    "    messages=chat_history\n",
    ")\n",
    "\n",
    "print(completion.to_json())\n",
    "\n",
    "# Add message to chat history\n",
    "chat_history.append({\n",
    "    \"role\": completion.choices[0].message.role,\n",
    "    \"content\": completion.choices[0].message.content\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all the histories and responses from the chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"role\": \"system\",\n",
      "        \"content\": \"You are a helpful assistant.\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"Tell me 5 funny fact about Quebec City.\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Sure! Quebec City is known for its rich history and unique culture, but it also has its share of quirky and amusing details. Here are five funny facts about Quebec City:\\n\\n1. **The \\\"Upside-Down\\\" Cannon**: Near the Plains of Abraham, Quebec City has a cannon that's famously stuck upside down into the ground. Its origins are a mystery, but local kids often joked it was to \\\"shoot at moles.\\\" The odd placement makes it one of the city's strange, unofficial landmarks, perfect for a funny photo op!\\n\\n2. **The \\\"Ice Cream War\\\"**: Quebecers are famously serious about their desserts, so it caused quite a stir when two popular ice cream shops in Old Quebec\\u2014\\u00c9rico and Chocolats Favoris\\u2014had a \\u201csweet rivalry\\u201d over whose ice cream was the best. The \\\"war\\\" may mostly exist in the minds of their fans, but locals love debating ice cream loyalty with dramatic flair.\\n\\n3. **The Poutine Police**: Quebec is the birthplace of poutine, but in Quebec City, locals can be a *little* judgmental about how it's made. Tourists trying to order \\\"healthy\\\" poutine or adding strange toppings (like pineapple!) might face mock gasps of horror from locals who view it as a food crime. Stick to the holy trinity: fries, cheese curds, and gravy.\\n\\n4. **The \\\"Leaning\\\" Ch\\u00e2teau Frontenac**: Though iconic and stunning, some mischievous locals joke that the Ch\\u00e2teau Frontenac has a slight \\\"lean\\\" if you're tipsy. It\\u2019s likely just a trick of your wine-glass-filled imagination, but it\\u2019s a fun excuse to enjoy one (or two) of Quebec's famed ciders or craft beers to \\\"check\\\" the angle.\\n\\n5. **Winter Carnival Canoe Races**: Every winter, Quebec City hosts a wild, icy canoe race across the frozen St. Lawrence River as part of the Winter Carnival. Participants paddle (and sometimes drag) their canoes across chunks of ice in what locals jokingly call \\u201cQuebec\\u2019s version of a spa day.\\u201d It's both hilarious and awe-inspiring to watch.\\n\\nQuebec City definitely knows how to mix history with humor. Whether it's through its quirky landmarks or offbeat traditions, there's always something to make you smile!\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(chat_history, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Give me more details related to the first fact ?\"\n",
    "})\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=chat_deployment_name,\n",
    "    messages=chat_history\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding with OpenAI ðŸŒŸ\n",
    "\n",
    "Embedding is a technique used to represent data in a continuous vector space. OpenAI leverages embeddings to enhance various applications, especially in natural language processing.\n",
    "\n",
    "## What is Embedding? ðŸ¤”\n",
    "\n",
    "Embedding transforms high-dimensional data into a lower-dimensional space, making it easier to process and analyze.\n",
    "\n",
    "## Why Use Embedding? ðŸ› ï¸\n",
    "\n",
    "1. **Dimensionality Reduction**: Simplifies data while preserving essential information.\n",
    "2. **Improved Performance**: Enhances model efficiency and accuracy.\n",
    "3. **Semantic Meaning**: Captures relationships between data points.\n",
    "\n",
    "## OpenAI and Embedding ðŸš€\n",
    "\n",
    "OpenAI uses embeddings to:\n",
    "- **Understand Text**: Represent words and sentences in a vector space.\n",
    "- **Improve Models**: Enhance the performance of language models.\n",
    "- **Analyze Data**: Reveal hidden patterns and relationships.\n",
    "\n",
    "## Conclusion ðŸŽ¯\n",
    "\n",
    "Embedding is a powerful tool in OpenAI's arsenal, enabling efficient data processing and improved model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.embeddings.create(input=\"This is an amazing cake, I love chocolate cake they are the best\", model=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒŸ Structured Outputs in JSON ðŸŒŸ\n",
    "\n",
    "JSON is one of the most widely used formats for data exchange in applications.\n",
    "\n",
    "## ðŸš€ Benefits of Structured Outputs\n",
    "\n",
    "- **Reliable type-safety**: Ensures correctly formatted responses without validation or retries.\n",
    "- **Explicit refusals**: Detect safety-based model refusals programmatically.\n",
    "- **Simpler prompting**: Achieve consistent formatting without strongly worded prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=chat_deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"},\n",
    "    ],\n",
    "    response_format=CalendarEvent,\n",
    ")\n",
    "\n",
    "event = completion.choices[0].message.parsed\n",
    "\n",
    "print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Structured Outputs you can provide the chain of thoughts and responses in a structured way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Step(BaseModel):\n",
    "    explanation: str\n",
    "    output: str\n",
    "\n",
    "class AnswerReasoning(BaseModel):\n",
    "    steps: list[Step]\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=chat_deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Guide the user through the answer step by step.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"}\n",
    "    ],\n",
    "    response_format=AnswerReasoning,\n",
    ")    \n",
    "\n",
    "answer_reasoning = completion.choices[0].message.parsed\n",
    "\n",
    "print(answer_reasoning.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒŸ Introduction to Function Calling with OpenAI Models\n",
    "\n",
    "Function calling enables developers to connect language models to external data and systems. You can define a set of functions as tools that the model has access to, and it can use them when appropriate based on the conversation history. You can then execute those functions on the application side, and provide results back to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sunny\n",
      "Hot and dry\n",
      "Unknown region\n"
     ]
    }
   ],
   "source": [
    "# Create a method that will return the weather in major region in Middle-Earth\n",
    "def get_weather(region: str) -> str:\n",
    "    weather_data = {\n",
    "        \"Shire\": \"Sunny\",\n",
    "        \"Mordor\": \"Hot and dry\",\n",
    "        \"Rivendell\": \"Mild and rainy\",\n",
    "        \"Gondor\": \"Warm and breezy\",\n",
    "        \"Rohan\": \"Windy\",\n",
    "        \"Mirkwood\": \"Foggy and damp\",\n",
    "        \"Isengard\": \"Stormy\",\n",
    "        \"Lothlorien\": \"Pleasant and cool\"\n",
    "    }\n",
    "    \n",
    "   # Normalize the region name to lower case for comparison\n",
    "    region = region.lower()\n",
    "    \n",
    "    for key in weather_data:\n",
    "        if key.lower() in region:\n",
    "            return weather_data[key]\n",
    "    \n",
    "    return \"Unknown region\"\n",
    "\n",
    "print(get_weather(\"Shire\"))  # Output: Sunny\n",
    "print(get_weather(\"Mordor\"))  # Output: Hot and dry\n",
    "print(get_weather(\"Unknown\"))  # Output: Unknown region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "  {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "          \"name\": \"get_weather_in_middle_earth_region\",\n",
    "          \"description\": \"Get the weather in a region in Middle-Earth. Call this whenever you need to know the weather in middle-earth, for example when an user asks 'What is the weather today in the Shire?'\",\n",
    "          \"parameters\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                  \"region\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"The region of middle-earth.\",\n",
    "                  },\n",
    "              },\n",
    "              \"required\": [\"region\"],\n",
    "              \"additionalProperties\": False,\n",
    "          },\n",
    "      }\n",
    "  }\n",
    "]\n",
    "\n",
    "chat_history =[]\n",
    "\n",
    "messages = [\n",
    "  {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are a helpful support assistant. Use the supplied tools to assist the user.\"\n",
    "  },\n",
    "  {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Hi, what is the weather today in the Shire?\"\n",
    "  }\n",
    "]\n",
    "\n",
    "chat_history.extend(messages)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=chat_deployment_name,\n",
    "  messages=messages,\n",
    "  tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-AkdRyoavOpyu9LDxuE0dcxtXK7V3g\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"tool_calls\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": null,\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"tool_calls\": [\n",
      "                    {\n",
      "                        \"id\": \"call_UlaJtqtP02bKEU31CopTVrIV\",\n",
      "                        \"function\": {\n",
      "                            \"arguments\": \"{\\\"region\\\":\\\"The Shire\\\"}\",\n",
      "                            \"name\": \"get_weather_in_middle_earth_region\"\n",
      "                        },\n",
      "                        \"type\": \"function\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            \"content_filter_results\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1735678098,\n",
      "    \"model\": \"gpt-4o-2024-11-20\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"system_fingerprint\": \"fp_82ce25c0d4\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 21,\n",
      "        \"prompt_tokens\": 119,\n",
      "        \"total_tokens\": 140,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    },\n",
      "    \"prompt_filter_results\": [\n",
      "        {\n",
      "            \"prompt_index\": 0,\n",
      "            \"content_filter_results\": {\n",
      "                \"hate\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"jailbreak\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"detected\": false\n",
      "                },\n",
      "                \"self_harm\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"sexual\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"violence\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Show if a function should be called\n",
    "print(response.to_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function\n",
    "tool_call = response.choices[0].message.tool_calls[0]\n",
    "\n",
    "if tool_call:\n",
    "    arguments = json.loads(tool_call.function.arguments) \n",
    "    function_call_result_message = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\n",
    "            \"region\": arguments.get(\"region\")        \n",
    "        }),\n",
    "        \"tool_call_id\": tool_call.id\n",
    "    }\n",
    "\n",
    "    # Call the model with the function call\n",
    "    chat_history.append(response.choices[0].message)\n",
    "    chat_history.append(function_call_result_message)\n",
    "\n",
    "    completion_payload = {\n",
    "        \"model\": chat_deployment_name,\n",
    "        \"messages\": chat_history    \n",
    "    }\n",
    "\n",
    "    response = client.chat.completions.create(model=completion_payload[\"model\"],\n",
    "                                              messages=completion_payload[\"messages\"])\n",
    "    \n",
    "    print(response.to_json(indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
