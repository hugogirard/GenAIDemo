{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 Official OpenAI SDK in Python\n",
    "\n",
    "Welcome to this notebook! In this notebook, we will be using the official OpenAI SDK in Python to interact with OpenAI's powerful language models. The SDK provides a simple and efficient way to access the capabilities of OpenAI's models, enabling us to perform a variety of tasks such as text generation, completion, and more.\n",
    "\n",
    "## 📦 Installation\n",
    "\n",
    "First, let's install the OpenAI SDK. You can do this using pip.\n",
    "\n",
    "## 📝 Usage\n",
    "\n",
    "Once the SDK is installed, you can start using it in your Python code. Set your OpenAI API key and make requests to the OpenAI API to get responses from the language models.\n",
    "\n",
    "## 📚 Documentation\n",
    "\n",
    "For more detailed information on how to use the OpenAI SDK, please refer to the official documentation.\n",
    "\n",
    "Happy coding! 🎉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai==1.58.1\n",
    "%pip install python-dotenv==1.0.1\n",
    "%pip install pandas==2.2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "chat_deployment_name = os.getenv(\"CHAT_DEPLOYMENT_NAME\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "base_url = os.getenv(\"OPENAI_BASE_URL\")\n",
    "embedding_model=os.getenv(\"EMBEDDING_MODEL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI  \n",
    "\n",
    "client = AzureOpenAI(api_key=api_key, azure_endpoint=base_url, api_version=\"2024-08-01-preview\")\n",
    "\n",
    "chat_history = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me 5 funny fact about Quebec City.\"\n",
    "        }\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=chat_deployment_name,\n",
    "    messages=chat_history\n",
    ")\n",
    "\n",
    "print(completion.to_json())\n",
    "\n",
    "# Add message to chat history\n",
    "chat_history.append({\n",
    "    \"role\": completion.choices[0].message.role,\n",
    "    \"content\": completion.choices[0].message.content\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all the histories and responses from the chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(chat_history, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Give me more details related to the first fact ?\"\n",
    "})\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=chat_deployment_name,\n",
    "    messages=chat_history\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding with OpenAI 🌟\n",
    "\n",
    "Embedding is a technique used to represent data in a continuous vector space. OpenAI leverages embeddings to enhance various applications, especially in natural language processing.\n",
    "\n",
    "## What is Embedding? 🤔\n",
    "\n",
    "Embedding transforms high-dimensional data into a lower-dimensional space, making it easier to process and analyze.\n",
    "\n",
    "## Why Use Embedding? 🛠️\n",
    "\n",
    "1. **Dimensionality Reduction**: Simplifies data while preserving essential information.\n",
    "2. **Improved Performance**: Enhances model efficiency and accuracy.\n",
    "3. **Semantic Meaning**: Captures relationships between data points.\n",
    "\n",
    "## OpenAI and Embedding 🚀\n",
    "\n",
    "OpenAI uses embeddings to:\n",
    "- **Understand Text**: Represent words and sentences in a vector space.\n",
    "- **Improve Models**: Enhance the performance of language models.\n",
    "- **Analyze Data**: Reveal hidden patterns and relationships.\n",
    "\n",
    "## Conclusion 🎯\n",
    "\n",
    "Embedding is a powerful tool in OpenAI's arsenal, enabling efficient data processing and improved model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.embeddings.create(input=\"This is an amazing cake, I love chocolate cake they are the best\", model=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🌟 Structured Outputs in JSON 🌟\n",
    "\n",
    "JSON is one of the most widely used formats for data exchange in applications.\n",
    "\n",
    "## 🚀 Benefits of Structured Outputs\n",
    "\n",
    "- **Reliable type-safety**: Ensures correctly formatted responses without validation or retries.\n",
    "- **Explicit refusals**: Detect safety-based model refusals programmatically.\n",
    "- **Simpler prompting**: Achieve consistent formatting without strongly worded prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Science Fair Attendance' date='Friday (specific date not provided)' participants=['Alice', 'Bob']\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=chat_deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"},\n",
    "    ],\n",
    "    response_format=CalendarEvent,\n",
    ")\n",
    "\n",
    "event = completion.choices[0].message.parsed\n",
    "\n",
    "print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Structured Outputs you can provide the chain of thoughts and responses in a structured way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Step(BaseModel):\n",
    "    explanation: str\n",
    "    output: str\n",
    "\n",
    "class AnswerReasoning(BaseModel):\n",
    "    steps: list[Step]\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=chat_deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Guide the user through the answer step by step.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"}\n",
    "    ],\n",
    "    response_format=AnswerReasoning,\n",
    ")    \n",
    "\n",
    "answer_reasoning = completion.choices[0].message.parsed\n",
    "\n",
    "print(answer_reasoning.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🌟 Introduction to Function Calling with OpenAI Models\n",
    "\n",
    "Function calling enables developers to connect language models to external data and systems. You can define a set of functions as tools that the model has access to, and it can use them when appropriate based on the conversation history. You can then execute those functions on the application side, and provide results back to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a method that will return the weather in major region in Middle-Earth\n",
    "def get_weather(region: str) -> str:\n",
    "    weather_data = {\n",
    "        \"Shire\": \"Sunny\",\n",
    "        \"Mordor\": \"Hot and dry\",\n",
    "        \"Rivendell\": \"Mild and rainy\",\n",
    "        \"Gondor\": \"Warm and breezy\",\n",
    "        \"Rohan\": \"Windy\",\n",
    "        \"Mirkwood\": \"Foggy and damp\",\n",
    "        \"Isengard\": \"Stormy\",\n",
    "        \"Lothlorien\": \"Pleasant and cool\"\n",
    "    }\n",
    "    \n",
    "   # Normalize the region name to lower case for comparison\n",
    "    region = region.lower()\n",
    "    \n",
    "    for key in weather_data:\n",
    "        if key.lower() in region:\n",
    "            return weather_data[key]\n",
    "    \n",
    "    return \"Unknown region\"\n",
    "\n",
    "print(get_weather(\"Shire\"))  # Output: Sunny\n",
    "print(get_weather(\"Mordor\"))  # Output: Hot and dry\n",
    "print(get_weather(\"Unknown\"))  # Output: Unknown region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "  {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "          \"name\": \"get_weather\",\n",
    "          \"strict\": True,\n",
    "          \"description\": \"Get the weather in a region in Middle-Earth. Call this whenever you need to know the weather in middle-earth, for example when an user asks 'What is the weather today in the Shire?'\",\n",
    "          \"parameters\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                  \"region\": {\n",
    "                      \"type\": \"string\",\n",
    "                      \"description\": \"The region of middle-earth.\",\n",
    "                  },\n",
    "              },\n",
    "              \"required\": [\"region\"],\n",
    "              \"additionalProperties\": False,\n",
    "          },\n",
    "      }\n",
    "  }\n",
    "]\n",
    "\n",
    "chat_history =[]\n",
    "\n",
    "messages = [\n",
    "  {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are a helpful support assistant. Use the supplied tools to assist the user.\"\n",
    "  },\n",
    "  {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Hi, what is the weather today in the Mirkwood?\"\n",
    "  }\n",
    "]\n",
    "\n",
    "chat_history.extend(messages)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=chat_deployment_name,\n",
    "  messages=messages,\n",
    "  tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-ApMTXCsfIb57BYAONGLbeqWdtPxnr\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"tool_calls\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": null,\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"tool_calls\": [\n",
      "                    {\n",
      "                        \"id\": \"call_ajvLEgcDjZfWF3H5GEfLK38q\",\n",
      "                        \"function\": {\n",
      "                            \"arguments\": \"{\\\"region\\\":\\\"Mirkwood\\\"}\",\n",
      "                            \"name\": \"get_weather\"\n",
      "                        },\n",
      "                        \"type\": \"function\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            \"content_filter_results\": {}\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1736804487,\n",
      "    \"model\": \"gpt-4o-2024-11-20\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"system_fingerprint\": \"fp_82ce25c0d4\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 16,\n",
      "        \"prompt_tokens\": 115,\n",
      "        \"total_tokens\": 131,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    },\n",
      "    \"prompt_filter_results\": [\n",
      "        {\n",
      "            \"prompt_index\": 0,\n",
      "            \"content_filter_results\": {\n",
      "                \"hate\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"jailbreak\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"detected\": false\n",
      "                },\n",
      "                \"self_harm\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"sexual\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                },\n",
      "                \"violence\": {\n",
      "                    \"filtered\": false,\n",
      "                    \"severity\": \"safe\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Show if a function should be called\n",
    "print(response.to_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foggy and damp\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "\n",
    "tool_call = response.choices[0].message.tool_calls[0]\n",
    "args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "result = get_weather(args[\"region\"])\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather today in Mirkwood is foggy and damp.\n"
     ]
    }
   ],
   "source": [
    "messages.append(response.choices[0].message)  # append model's tool call message\n",
    "messages.append({                               # append result message\n",
    "    \"role\": \"tool\",\n",
    "    \"tool_call_id\": tool_call.id,\n",
    "    \"content\": result\n",
    "})\n",
    "\n",
    "completion_2 = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "print(completion_2.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
